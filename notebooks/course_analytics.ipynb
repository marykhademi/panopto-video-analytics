{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 1: Data Import and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libaries and packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load and examine the dataframe structure\n",
    "file_path = \"../data/raw/df.xlsx\"\n",
    "data = pd.ExcelFile(file_path)\n",
    "\n",
    "# All courses (sheets) except first two sheets (metadata)\n",
    "course_list = [sheet for sheet in data.sheet_names if sheet not in ['List of Courses', 'Data Points Defined']]\n",
    "\n",
    "print(f\"There are {len(course_list)} courses in this excel file, which are:\")\n",
    "for i, course in enumerate(course_list):\n",
    "    print(f\"{i+1}. {course}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 2: Combine all courses (sheets) into one sheet\n",
    "\n",
    "This function combines multiple courses (sheets) into one single sheet (dataframe) by handling course codes with or without spaces (e.g., \"XXXX2000\" or \"XXXX 2000\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining all courses (sheets)\n",
    "\n",
    "all_courses = []\n",
    "for course in course_list:\n",
    "    course_df = data.parse(course)\n",
    "    course_df['course_identifier'] = course\n",
    "    all_courses.append(course_df)\n",
    "\n",
    "data = pd.concat(all_courses, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_course_identifier(df, col_name):\n",
    "    def parse_single(identifier):\n",
    "        if pd.isna(identifier):\n",
    "            return pd.Series(['Unknown', 'Unknown', 'Unknown'])\n",
    "        \n",
    "        pattern = r'^([A-Z]+)\\s?(\\d+)\\s+([A-Za-z]+)\\s+(\\d{4})$'\n",
    "        match = re.match(pattern, str(identifier).strip())\n",
    "        \n",
    "        if match:\n",
    "            course_code = f\"{match.group(1)} {match.group(2)}\"\n",
    "            term = match.group(3)\n",
    "            year = match.group(4)\n",
    "            return pd.Series([course_code, term, year])\n",
    "        else:\n",
    "            return pd.Series(['Unknown', 'Unknown', 'Unknown'])\n",
    "    \n",
    "    df[['course_code', 'term', 'year']] = df[col_name].apply(parse_single)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_columns(df):\n",
    "    df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('-', '_')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply functions to standardize the column names\n",
    "df = parse_course_identifier(data, 'course_identifier')\n",
    "data = standardize_columns(data)\n",
    "data['course_code'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display column names\n",
    "print(f\"\\nList of new dataset columns:\")\n",
    "for i, col in enumerate(data.columns):\n",
    "    print(f\"{i+1}. {col}\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 3: Data Quality Assessment\n",
    "\n",
    "- look for negative and missing values, outliers by checking the range (min, max)\n",
    "- write a summary on the table means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and display a summary table \n",
    "summary_table = []\n",
    "\n",
    "for col in data.columns:\n",
    "    empty_count = data[col].isna().sum()\n",
    "    numeric_column = pd.to_numeric(data[col], errors = 'coerce')\n",
    "    neg_count = (numeric_column < 0).sum()\n",
    "    min_val = numeric_column.min()\n",
    "    max_val = numeric_column.max()\n",
    "    \n",
    "    summary_table.append({\n",
    "        'Column Name': col,\n",
    "        'Empty Value': empty_count,\n",
    "        'Negative Value': neg_count,\n",
    "        'Min Value': f'{min_val:.2f}' if pd.notna(min_val) else 'N/A',\n",
    "        'Max Value': f'{max_val:.2f}' if pd.notna(max_val) else 'N/A',\n",
    "        'Column Data Type': data[col].dtype,\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(summary_table)\n",
    "display(summary)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phase 4: Analysis\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
